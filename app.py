import streamlit as st
import tempfile
import mediapipe as mp
import cv2
import time
import numpy as np
import os
from core.geometry import calculate_angle, get_landmark_coords
from core.visualizer import draw_analysis_overlay

# --- 1. ç³»çµ±è¨­å®š ---
st.set_page_config(layout="wide", page_title="Coach's Eye Pro - Full Body Export")

# è®Šæ•¸åˆå§‹åŒ–
uploaded_file = None
tfile = None

# --- CSS å„ªåŒ– (ä¿ç•™åŸæœ¬çš„ HUD é¢¨æ ¼) ---
st.markdown("""
<style>
    .stApp { background-color: #0E1117; color: #FAFAFA; }
    [data-testid="stSidebar"] { background-color: #262730; border-right: 1px solid #333; }
    
    /* æŒ‰éˆ•æ¨£å¼ */
    .stButton > button { 
        border: 1px solid #00FF00; color: #00FF00; background: transparent; width: 100%;
        font-weight: bold; padding: 10px;
    }
    .stButton > button:hover { background-color: #00FF00; color: #000; box-shadow: 0 0 15px rgba(0,255,0,0.6); }
    
    /* é€²åº¦æ¢æ¨£å¼ */
    .stProgress > div > div > div > div { background-color: #00FF00; }
    
    /* å¤šé¸å–®æ¨£å¼ */
    .stMultiSelect [data-baseweb="tag"] { background-color: #333 !important; border: 1px solid #00FF00 !important; }
    
    #MainMenu {visibility: hidden;} footer {visibility: hidden;} header {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# --- é—œéµæ›´æ–°ï¼šå…¨èº«ç”Ÿç‰©åŠ›å­¸é—œç¯€è¨­å®š (Full Body Config) ---
# æ ¼å¼: (èµ·é», é ‚é», çµ‚é», é¡è‰²RGB)
# é¡è‰²: æ©˜è‰²(å·¦å´)=(255, 165, 0), ç´«è‰²(å³å´)=(147, 112, 219)
JOINT_CONFIG = {
    # --- ä¸‹è‚¢ (Lower Body) ---
    "å³è† (R. Knee)":    (24, 26, 28, (147, 112, 219)), # é«–-è†-è¸
    "å·¦è† (L. Knee)":     (23, 25, 27, (255, 165, 0)),
    "å³é«– (R. Hip)":      (12, 24, 26, (147, 112, 219)), # è‚©-é«–-è† (è»€å¹¹è§’åº¦)
    "å·¦é«– (L. Hip)":      (11, 23, 25, (255, 165, 0)),
    "å³è¸ (R. Ankle)":    (26, 28, 32, (147, 112, 219)), # è†-è¸-è¶³å°– (æ¨è¹¬åˆ†æ)
    "å·¦è¸ (L. Ankle)":    (25, 27, 31, (255, 165, 0)),

    # --- ä¸Šè‚¢ (Upper Body) ---
    "å³è‚˜ (R. Elbow)":    (12, 14, 16, (147, 112, 219)), # è‚©-è‚˜-è…•
    "å·¦è‚˜ (L. Elbow)":    (11, 13, 15, (255, 165, 0)),
    "å³è‚© (R. Shoulder)": (14, 12, 24, (147, 112, 219)), # è‚˜-è‚©-é«– (æ“ºè‡‚å¹…åº¦)
    "å·¦è‚© (L. Shoulder)": (13, 11, 23, (255, 165, 0)),
}

# MediaPipe åˆå§‹åŒ– (ä½¿ç”¨ Full æ¨¡å¼ä»¥ç²å¾—æœ€é«˜ç²¾åº¦)
mp_pose = mp.solutions.pose
pose = mp_pose.Pose(
    static_image_mode=False, 
    model_complexity=1, 
    min_detection_confidence=0.5, 
    min_tracking_confidence=0.5
)
mp_drawing = mp.solutions.drawing_utils

# --- æ ¸å¿ƒè™•ç†å‡½å¼ (èƒŒæ™¯è½‰æª”å¼•æ“) ---
def process_video_background(input_path, output_path, selected_joints, progress_bar, status_text):
    cap = cv2.VideoCapture(input_path)
    
    # å–å¾—å½±ç‰‡è³‡è¨Š
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    # è¨­å®šå½±ç‰‡å¯«å…¥å™¨
    fourcc = cv2.VideoWriter_fourcc(*'mp4v') 
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    frame_count = 0
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        # 1. åµæ¸¬éª¨æ¶
        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        image.flags.writeable = False
        results = pose.process(image)
        image.flags.writeable = True
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

        # 2. ç¹ªåœ–
        if results.pose_landmarks:
            # ç•«åŸºç¤éª¨æ¶ (æ·¡ç°è‰²ï¼Œé¿å…æ¶çœ¼)
            mp_drawing.draw_landmarks(
                image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,
                mp_drawing.DrawingSpec(color=(80,80,80), thickness=2, circle_radius=2),
                mp_drawing.DrawingSpec(color=(200,200,200), thickness=2, circle_radius=2)
            )
            
            landmarks = results.pose_landmarks.landmark
            
            # ç•«æ‰€æœ‰è¢«å‹¾é¸çš„é—œç¯€
            for joint_name in selected_joints:
                p1_id, p2_id, p3_id, color = JOINT_CONFIG[joint_name]
                try:
                    p1 = get_landmark_coords(landmarks, (height, width, 3), p1_id)
                    p2 = get_landmark_coords(landmarks, (height, width, 3), p2_id)
                    p3 = get_landmark_coords(landmarks, (height, width, 3), p3_id)
                    
                    angle = calculate_angle(p1, p2, p3)
                    
                    # ç¹ªè£½ç–ŠåŠ å±¤
                    image = draw_analysis_overlay(image, p1, p2, p3, angle, color=color)
                except IndexError:
                    continue

        # 3. å¯«å…¥
        out.write(image)
        
        # 4. æ›´æ–° UI
        frame_count += 1
        progress = frame_count / total_frames
        progress_bar.progress(progress)
        status_text.text(f"æ­£åœ¨é‹ç®—å…¨èº«ç”Ÿç‰©åŠ›å­¸æ•¸æ“š... {int(progress*100)}% ({frame_count}/{total_frames})")

    cap.release()
    out.release()
    return True

# --- ä¸»ç¨‹å¼ UI ---
st.sidebar.title("ğŸ”§ è¨­å®šä¸­å¿ƒ")
uploaded_file = st.sidebar.file_uploader("1. ä¸Šå‚³å½±ç‰‡", type=['mp4', 'mov', 'avi'])

st.sidebar.markdown("---")
# é è¨­å‹¾é¸å¸¸ç”¨çš„ä¸‹è‚¢é—œç¯€
selected_joints = st.sidebar.multiselect(
    "2. é¸æ“‡è¦ç–ŠåŠ çš„æ•¸æ“š:",
    options=list(JOINT_CONFIG.keys()),
    default=["å³è† (R. Knee)", "å³é«– (R. Hip)", "å³è¸ (R. Ankle)"]
)

if uploaded_file:
    # è™•ç†æš«å­˜è·¯å¾‘
    tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') 
    tfile.write(uploaded_file.read())
    
    # å»ºç«‹è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
    output_temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
    output_path = output_temp_file.name
    
    cap = cv2.VideoCapture(tfile.name)
    st.info(f"å½±ç‰‡å·²è¼‰å…¥: {int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))}x{int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))} @ {int(cap.get(cv2.CAP_PROP_FPS))}FPS")
    cap.release()

    if st.button("ğŸš€ é–‹å§‹èƒŒæ™¯é‹ç®— (Start Processing)"):
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        with st.spinner("AI æ­£åœ¨é€å¹€åˆ†æå…¨èº«é—œç¯€ï¼Œè«‹ç¨å€™..."):
            success = process_video_background(tfile.name, output_path, selected_joints, progress_bar, status_text)
        
        if success:
            status_text.success("âœ… åˆ†æå®Œæˆï¼å½±ç‰‡å·²ç”Ÿæˆã€‚")
            progress_bar.empty()
            
            st.divider()
            col1, col2 = st.columns([0.7, 0.3])
            
            with col1:
                st.subheader("ğŸ¬ åˆ†æçµæœ")
                # é€™è£¡ä½¿ç”¨åŸç”Ÿçš„ Streamlit æ’­æ”¾å™¨ï¼Œæ”¯æ´æ‹–æ‹‰ã€å…¨è¢å¹•
                st.video(output_path)
            
            with col2:
                st.subheader("ğŸ“¥ åŒ¯å‡ºå ±å‘Š")
                st.write("å½±ç‰‡å·²åŒ…å«å®Œæ•´çš„é—œç¯€è§’åº¦æ•¸æ“šã€‚")
                
                with open(output_path, 'rb') as f:
                    video_bytes = f.read()
                    
                st.download_button(
                    label="â¬‡ï¸ ä¸‹è¼‰åˆ†æå½±ç‰‡ (MP4)",
                    data=video_bytes,
                    file_name="full_body_analysis.mp4",
                    mime="video/mp4"
                )
else:
    st.info("ğŸ‘ˆ è«‹å¾å·¦å´ä¸Šå‚³å½±ç‰‡ä»¥é–‹å§‹ã€‚")